{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load libraries และ เตรียมรูปภาพให้อยู่ในรูปแบบ Matrix เช่นเดิม เราต้องการ flatten 3D 64 * 64 * 3 ให้อยู่ในรูป 1D 12288 และ normalize ค่าให้อยู่ใน range 0 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "\n",
    "train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes = pkl.load(open('../data/dataset64.pkl', 'rb'))\n",
    "\n",
    "# transform shapes from [m, 64, 64, 3] to [m, 64 * 64 * 3]\n",
    "train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1)\n",
    "test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1)\n",
    "# transform values from 0-255 to 0-1\n",
    "train_set_x = train_set_x_flatten/255.\n",
    "test_set_x = test_set_x_flatten/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สำหรับการคำนวณใน TensorFlow นั้น รูปแบบมาตรฐานในการวาง Matrix จะเป็น [m, n] คือจำนวน examples m อยู่แนว row และ จำนวน features n อยู่แนว column ซึ่งต่างจากที่เรียนใน class ดังนั้น ต้องมีการ convert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set x:[400, 12288]\n",
      "test set x:[50, 12288]\n",
      "train set y:[400, 1]\n",
      "test set y:[50, 1]\n"
     ]
    }
   ],
   "source": [
    "train_set_y = train_set_y_orig.T\n",
    "test_set_y = test_set_y_orig.T\n",
    "print('train set x:[%d, %d]' % train_set_x.shape)\n",
    "print('test set x:[%d, %d]' % test_set_x.shape)\n",
    "print('train set y:[%d, %d]' % train_set_y.shape)\n",
    "print('test set y:[%d, %d]' % test_set_y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "การ program TensorFlow เริ่มจากการกำหนด Computational Graph  ใน graph เราเริ่มจากกำหนด input และ output คือ x และ y ที่เราจะให้ model เรียนรู้<br><br>\n",
    "เนื่องจาก model เราจะต้องสามารถรับ input ของรูปภาพรูปเดียว หรือ หลาย ๆ รูปได้ ทั้งในตอน training และ prediction แต่ส่วนใหญ่เราจะทราบถึง shape และค่า ที่แน่นอนของ x และ y ก็เมื่อจะเริ่ม train หรือเริ่ม predict ดังนั้น input และ output จะไม่มีทั้งค่าและขนาดของ matrix ใน dimension m ที่ตายตัว ส่วนด้าน n ของ x นั้น เราสามารถกำหนดให้ตายตัวได้\n",
    "ใน TensorFlow data structure ที่ใช้รองรับค่าที่สามารถเปลี่ยนไปได้ตามที่เรากำหนดในการ run แต่ละครั้งคือ placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = train_set_x.shape[1]\n",
    "\n",
    "X = tf.placeholder(tf.float64, shape=(None, n), name=\"X\")\n",
    "Y = tf.placeholder(tf.float64, shape=(None), name=\"Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "การประกาศ placeholder ในด้านบน จะเห็นว่า เรากำหนด None ในด้าน m เนื่องจากเรายังไม่รู้ว่า m มีเท่าไหร่ แต่ถ้าเรากำหนดตายตัวว่า m คือ 400 model เราก็จะทำงานต่อเมื่อ m = 400 เท่านั้น ถ้าเราต้องการจะ train รูปภาพอื่นๆ หรือแบ่งส่วน training set เป็นชุดย่อยๆ ก็ไม่สามารถทำได้\n",
    "<br><br>\n",
    "placeholder เป็น tensor ชนิดหนึ่ง เราสามารถคิดได้ว่า tensor คือ matrix ที่อยู่ใน TensorFlow<br><br>\n",
    "TensorFlow จริงๆแล้วทำงานอยู่บน process ของตัวเอง เมื่อเราสร้าง tensor ที่เก็บข้อมูลต่างๆจะถูกสร้างขึ้นมาใน TensorFlow process ใน python เราจะมีแค่ตัวแปรที่อ้างถึง tensor ได้เท่านั้น<br><br>\n",
    "เมื่อ print tensor เราจะเห็นแค่คำอธิบายของมันเท่านั้น ข้อมูลที่อยู่ข้างในอยู่ใน TensorFlow Process เราจะนำค่ามาแสดงใน python ได้ก็ต่อเมื่อเราทำการ run session<br><br>\n",
    "จุดนี้ คล้ายๆกับที่เราสร้าง diagram ใน SSIS ซึ่งจะเป็นกล่องๆและมีเส้นลากเชื่อมกล่อง กล่องคือการ input, transform data ส่วนเส้นที่ลากคือการไหลของข้อมูล เราจะยังไม่เห็นข้อมูลอะไรทั้งสิ้น ถ้าเราไม่ได้เริ่ม run session และการสร้าง computational graph คือการแค่วางกล่องและลากเส้นเข้าเชื่อมกัน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"X:0\", shape=(?, 12288), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ใน model Logistic Regression สิ่งที่เราต้องการเรียน คือค่าตัวแปร W, b ค่า W, b จะถูก set ขึ้นมาใน step แรกด้วยการสุ่ม และแต่ละ step ค่าจะถูกเปลี่ยนไปตามทิศทางของ gradient<br>ในการ run แต่ละ step TensorFlow จะต้องสามารถจำค่า W, b ใน step ก่อนหน้านั้นได้ จุดนี้จะต่างจาก placeholder ทุกครั้งที่เรา run แต่ละ step นั้น เราจะส่งค่าที่จะใช้ในแต่ละรอบผ่าน placeholder ในขณะที่ W และ b จะอยู่ใน TensorFlow ตลอด กรณีนี้ เราจะใช้ Variable ซึ่งเป็น Tensor อีกชนิดหนึ่ง"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.get_variable(name=\"W\", shape=(n, 1), dtype=tf.float64)\n",
    "b = tf.get_variable(name=\"b\", shape=(1), dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สังเกตว่า dimension ของ W จะไม่เหมือนที่เรียนใน class คือเป็น vector แนวตั้งแทนที่จะเป็นแนวนอน ซึ่งตรงนี้จะสอดคล้องกับ dimension ของ X ที่เปลี่ยนไปด้วยเช่นกัน<br><br>\n",
    "ต่อไป เราต้องคำนวณ X * W + b ตรงนี้เรามีทางเลือกที่จะใช้ tf.matmul(X, W) + b แต่เนื่องจาก operation นี้เป็น operation ที่ใช้กันบ่อยมาก จึงมีฟังก์ชั่นเฉพาะ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = tf.nn.xw_plus_b(X, W, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สังเกตว่า ใน documentation จะเรียก W ว่า Weight และ b ว่า bias<br>\n",
    "z นั้น ใน logistic regression มีชื่อเรียกเฉพาะว่า logits และการใช้ function sigmoid ครอบและไปเทียบกัย labels โดยใช้ cross entropy เพื่อคำนวณ loss นั้น\n",
    "ก็เป็นการคำนวณที่ใช้บ่อย จึงมี function มาตรฐานให้ใช้ ซึ่งฟังก์ชั่นนี้ก็คำนวณค่า -y*log(a) - (1-y)*log(1-a) นั่นเอง"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses = tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "losses ด้านบนจะมี shape เช่นเดียวกับ Y คือ (n) ซึ่งในแต่ละค่าภายใน คือค่า loss ของแต่ละ example<br>\n",
    "ค่าเฉลี่ยรวมหรือ cost function นั่นก็คำนวณได้จากการหาค่า mean ซึ่งใน TensorFlow ใช้ function reduce_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สุดท้าย เราต้องการจะ optimize cost นี้ โดยใช้ gradient descent algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_op = tf.train.GradientDescentOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "magic ของ TensorFlow อยู่ที่บรรทัดด้านบน เนื่องจากเราได้กำหนด computational graph คือ forward propagation เรียบร้อย ด้าน backward propagation คือ การคำนวณหา gradient และ apply gradient นั้น TensorFlow สามารถหาวิธีทำให้เราโดยอัตโนมัติ ในด้านการกำหนด computational graph นั้น สิ้นสุดแค่นี้<br><br>\n",
    "แต่ก่อนที่จะมีการ run นั้น เรามีการกำหนดตัวแปร W และ b ซึ่งต้องมีการสุ่มค่า operation ในการสุ่มค่านี้ เราสามารถเลือกที่จะสุ่มอย่างไรก็ได้ แต่เพื่อความสะดวก TensorFlow มีฟังก์ชั่นในการสุ่มค่าทุกตัวแปรให้เรา"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ขั้นตอนถัดไปจะเป็นขั้นตอนการ run session\n",
    "session ในที่นี้ก็คือ runtime เราสามารถสั่ง run ทีละ step ได้ ในการ run แต่ละครั้ง เราต้องระบุส่วนของ computational graph ที่เราต้องการ run และค่าที่เราอยากจะได้จากการ run นั้นๆ เราสามารถสร้าง session ได้ด้วย function tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "การ run จะเริ่มด้วยการ initialize variables เสมอ<br>\n",
    "จากนั้นก็เป็น loop ในการ apply gradient ในแต่ละ step\n",
    "ในแต่ละ step เราจะกำหนด input X, output Y ผ่าน feed_dict เข้าไปใน session และดึงค่า z กลับมาเพื่อคำนวณ accuracy<br>\n",
    "แต่การ run session นั้น มีกฎอยู่อย่างหนึ่งคือ มันจะ run เท่าที่จำเป็นในการดึงค่าตัวแปรที่เราอยากได้กลับมาเท่านั้น\n",
    "ถ้าย้อนไปดู computational graph จะเห็นว่า ค่า z คำนวณก่อนที่มีการทำ optimization ดังนั้น เราต้องระบุ operation สุดท้ายที่ TensorFlow ควรจะ run คือ train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0: accuracy = 0.4950\n",
      "iter 100: accuracy = 0.7925\n",
      "iter 200: accuracy = 0.8175\n",
      "iter 300: accuracy = 0.8175\n",
      "iter 400: accuracy = 0.8175\n",
      "iter 500: accuracy = 0.8250\n",
      "iter 600: accuracy = 0.8325\n",
      "iter 700: accuracy = 0.8375\n",
      "iter 800: accuracy = 0.8475\n",
      "iter 900: accuracy = 0.8475\n",
      "iter 1000: accuracy = 0.8575\n",
      "iter 1100: accuracy = 0.8600\n",
      "iter 1200: accuracy = 0.8600\n",
      "iter 1300: accuracy = 0.8625\n",
      "iter 1400: accuracy = 0.8625\n",
      "iter 1500: accuracy = 0.8650\n",
      "iter 1600: accuracy = 0.8675\n",
      "iter 1700: accuracy = 0.8700\n",
      "iter 1800: accuracy = 0.8700\n",
      "iter 1900: accuracy = 0.8725\n",
      "iter 2000: accuracy = 0.8750\n",
      "iter 2100: accuracy = 0.8750\n",
      "iter 2200: accuracy = 0.8775\n",
      "iter 2300: accuracy = 0.8800\n",
      "iter 2400: accuracy = 0.8800\n",
      "iter 2500: accuracy = 0.8825\n",
      "iter 2600: accuracy = 0.8875\n",
      "iter 2700: accuracy = 0.8900\n",
      "iter 2800: accuracy = 0.8950\n",
      "iter 2900: accuracy = 0.9000\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "for i in range(3000):\n",
    "    _, pred_logits = sess.run([train_op, z], feed_dict={X:train_set_x, Y:train_set_y})\n",
    "    pred = (pred_logits > 0).astype(train_set_y.dtype)\n",
    "    accuracy = np.mean(pred == train_set_y)\n",
    "    if i % 100 == 0:\n",
    "        print(\"iter %d: accuracy = %0.4f\" % (i, accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ค่า test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy = 0.7800\n"
     ]
    }
   ],
   "source": [
    "pred_logits = sess.run(z, feed_dict={X:test_set_x})\n",
    "pred = (pred_logits > 0).astype(test_set_y.dtype)\n",
    "accuracy = np.mean(pred == test_set_y)\n",
    "print('test set accuracy = %0.4f' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สุดท้าย อย่าลืม close session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
